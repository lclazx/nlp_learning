{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "classify_text_with_tf_hub.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lclazx/nlp_learning/blob/master/classify_text_with_tf_hub.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IayINtXQNiMY",
        "colab_type": "text"
      },
      "source": [
        "# 引入资源和设计辅助类、函数"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zP33UKQRPRfO",
        "colab_type": "code",
        "outputId": "a20f2a30-8200-4ee4-d8f9-8f7b20794f0a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 64
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JsAFw4xjYwV8",
        "colab_type": "code",
        "outputId": "3987b638-8685-4926-e00b-3308f71cee36",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "tf.__version__"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'1.15.0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BEPitQZ_Y5uA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fhW-HJRIk0kt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class InputFeature(object):\n",
        "  def __init__(self,\n",
        "         input_ids,\n",
        "         input_mask,\n",
        "         segment_ids,\n",
        "         label_ids,\n",
        "         is_real_example=True):\n",
        "    self.input_ids = input_ids\n",
        "    self.input_mask = input_mask\n",
        "    self.segment_ids = segment_ids\n",
        "    self.label_ids = label_ids\n",
        "    self.is_real_example = is_real_example\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q2dNWPj9HZAl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def input_fn_builder(features, seq_length, is_training, num_labels, drop_remainder):\n",
        "  all_input_ids = []\n",
        "  all_input_mask = []\n",
        "  all_segment_ids = []\n",
        "  all_label_ids = []\n",
        "\n",
        "  for feature in features:\n",
        "    all_input_ids.append(feature.input_ids)\n",
        "    all_input_mask.append(feature.input_mask)\n",
        "    all_segment_ids.append(feature.segment_ids)\n",
        "    all_label_ids.append(feature.label_ids)\n",
        "\n",
        "    def input_fn(params):\n",
        "      batch_size = params['batch_size']\n",
        "      num_examples = len(features)\n",
        "      d = tf.data.Dataset.from_tensor_slices({\n",
        "          'input_ids': \n",
        "            tf.constant(\n",
        "                all_input_ids, shape=[num_examples, seq_length],\n",
        "                dtype=tf.int32),\n",
        "          'input_mask':\n",
        "            tf.constant(all_input_mask, shape=[num_examples, seq_length], dtype=tf.int32),\n",
        "          'segment_ids':\n",
        "            tf.constant(all_segment_ids, shape=[num_examples, seq_length], dtype=tf.int32),\n",
        "          'label_ids':\n",
        "            tf.constant(all_label_ids, shape=[num_examples, num_labels], dtype=tf.int32)\n",
        "      })\n",
        "\n",
        "      if is_training:\n",
        "        d = d.repeat()\n",
        "        d = d.shuffle(buffer_size=100)\n",
        "      d = d.batch(batch_size=batch_size, drop_remainder=drop_remainder)\n",
        "      return d\n",
        "    return input_fn"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J1yIBuuD0b2N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def convert_single_example(ex_index, example, label_list, max_seq_length, tokenizer):\n",
        "  label_map = {}\n",
        "  # for(i, label) in enumrate(label_list):\n",
        "  #   label_map[label] = id\n",
        "  tokens_a = tokenizer.tokenize(example.text_a)\n",
        "  tokens_b = None\n",
        "\n",
        "  if len(tokens_a) > max_seq_length - 2:\n",
        "    tokens_a = tokens_a[0: (max_seq_length - 2)]\n",
        "  tokens = []\n",
        "  segment_ids = []\n",
        "  tokens.append('[CLS]')\n",
        "  segment_ids.append(0)\n",
        "  for token in tokens_a:\n",
        "    tokens.append(token)\n",
        "    segment_ids.append(0)\n",
        "  tokens.append('[SEP]')\n",
        "  segment_ids.append(0)\n",
        "\n",
        "  input_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
        "  input_mask = [1] * len(input_ids)\n",
        "\n",
        "  while len(input_ids) < max_seq_length:\n",
        "    input_ids.append(0)\n",
        "    input_mask.append(0)\n",
        "    segment_ids.append(0)\n",
        "\n",
        "  assert len(input_ids) == max_seq_length\n",
        "  assert len(input_mask) == max_seq_length\n",
        "  assert len(segment_ids) == max_seq_length\n",
        "\n",
        "  label_ids = [0] * len(label_list)\n",
        "  for label in example.label:\n",
        "    label_ids[label] = 1\n",
        "\n",
        "  feature = InputFeature(input_ids=input_ids, input_mask = input_mask, segment_ids = segment_ids, label_ids = label_ids, is_real_example=True)\n",
        "  return feature\n",
        "\n",
        "def conver_examples_to_features(examples, label_list, max_seq_length, tokenizer):\n",
        "  features=[]\n",
        "  for(ex_index, example) in enumerate(examples):\n",
        "    if ex_index%10000 == 0:\n",
        "      tf.logging.info(\"Writing example %d of %d\" % (ex_index, len(examples)))\n",
        "    feature = convert_single_example(ex_index, example, label_list, max_seq_length, tokenizer)\n",
        "    features.append(feature)\n",
        "  return features\n",
        "\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7EhdZEX9OSfg",
        "colab_type": "text"
      },
      "source": [
        "# 步骤1\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vrBahmptNrYi",
        "colab_type": "text"
      },
      "source": [
        "## 引用 google cloud service 包， 并下载文件"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IW7HCdhKOUNm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "from googleapiclient.discovery import build\n",
        "gcs_service = build('storage', 'v1')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GNyvdG1MOk5p",
        "colab_type": "text"
      },
      "source": [
        "## 创建输出目录"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "75Cyi_G-OiKQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "OUTPUT_DIR = 'training_output' #@param\n",
        "DO_DELETE =  False#@param\n",
        "USE_BUCKET = True #@param\n",
        "BUCKET = 'bert_classification'\n",
        "\n",
        "if USE_BUCKET:\n",
        "  OUTPUT_DIR = 'gs://{}/{}'.format(BUCKET, OUTPUT_DIR)\n",
        "  \n",
        "if DO_DELETE:\n",
        "  try:\n",
        "    tf.gfile.DeleteRecursively(OUTPUT_DIR)\n",
        "  except:\n",
        "    pass\n",
        "tf.gfile.MakeDirs(OUTPUT_DIR)\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b5ZkkpQmPffm",
        "colab_type": "text"
      },
      "source": [
        "## 下载文件"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e-7LVYsKPj1z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "551d04b1-fec9-47e1-8238-fd718e262378"
      },
      "source": [
        "from apiclient.http import MediaIoBaseDownload\n",
        "def download_file(output_dir, source_file):\n",
        "  with open(output_dir, 'wb') as f:\n",
        "    request = gcs_service.objects().get_media(bucket=BUCKET, object=source_file)\n",
        "    media = MediaIoBaseDownload(f, request)\n",
        "    done = False\n",
        "    while not done:\n",
        "      _, done = media.next_chunk()\n",
        "\n",
        "download_file(output_dir='/tmp/train_data.json', source_file='raw_data/train_data.json/train_data.json')\n",
        "download_file(output_dir='/tmp/test_data.json', source_file='raw_data/test_data_postag.json/test_data_postag.json')\n",
        "download_file(output_dir='/tmp/dev_data.json', source_file='raw_data/dev_data.json/dev_data.json')\n",
        "\n",
        "print('Downloaded')"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloaded\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3UuX9nlwRAMO",
        "colab_type": "text"
      },
      "source": [
        "# 步骤2\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z0vVRnxBNt8O",
        "colab_type": "text"
      },
      "source": [
        "## 准备样本"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YiVfDpIzRE9N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import json\n",
        "import pandas as pd\n",
        "def prepare_data(input_file, is_training=True, predicate_list=None, limit=None):\n",
        "  if not predicate_list:\n",
        "    predicate_list = []\n",
        "  data = {\n",
        "      'text':[],\n",
        "      'labels':[]      \n",
        "  }\n",
        "  with open(input_file, 'r') as f:\n",
        "    for (index, line) in enumerate(f):\n",
        "      if limit and index>=limit:\n",
        "        break\n",
        "      if index % 10000 == 0:\n",
        "        print('sample {}', index)\n",
        "      line_data = json.loads(line)\n",
        "      text = line_data['text']\n",
        "      data['text'].append(text)\n",
        "      labels = []\n",
        "      for spo in line_data['spo_list']:\n",
        "        predicate = spo['predicate']\n",
        "        if is_training:\n",
        "          if predicate_list.count(predicate) == 0:\n",
        "            predicate_list.append(predicate)\n",
        "        else:\n",
        "          if predicate_list.count(predicate) == 0:\n",
        "            continue\n",
        "\n",
        "        predicate_index = predicate_list.index(predicate)\n",
        "        if labels.count(predicate_index) == 0:\n",
        "          labels.append(predicate_index)\n",
        "      data['labels'].append(labels)\n",
        "  return pd.DataFrame.from_dict(data), predicate_list"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "knk3fVWjUBHV",
        "colab_type": "text"
      },
      "source": [
        "## 获取训练数据"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ly5mZ56hUDxT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 341
        },
        "outputId": "bb620885-8842-44a7-e926-9a5c6279c3bf"
      },
      "source": [
        "train_data, predicate_list = prepare_data('/tmp/train_data.json')"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "sample {} 0\n",
            "sample {} 10000\n",
            "sample {} 20000\n",
            "sample {} 30000\n",
            "sample {} 40000\n",
            "sample {} 50000\n",
            "sample {} 60000\n",
            "sample {} 70000\n",
            "sample {} 80000\n",
            "sample {} 90000\n",
            "sample {} 100000\n",
            "sample {} 110000\n",
            "sample {} 120000\n",
            "sample {} 130000\n",
            "sample {} 140000\n",
            "sample {} 150000\n",
            "sample {} 160000\n",
            "sample {} 170000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OoIOttDaZm4w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0MHiOXY5dSMj",
        "colab_type": "text"
      },
      "source": [
        "# 步骤3\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E8ly4q8NNv8D",
        "colab_type": "text"
      },
      "source": [
        "## 引入BERT"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NfH2my6ndVEo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 161
        },
        "outputId": "54242521-4a9c-442e-947d-0dbab23c462c"
      },
      "source": [
        "!pip install bert-tensorflow\n",
        "\n",
        "import bert\n",
        "from bert import run_classifier\n",
        "from bert import optimization\n",
        "from bert import tokenization"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting bert-tensorflow\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a6/66/7eb4e8b6ea35b7cc54c322c816f976167a43019750279a8473d355800a93/bert_tensorflow-1.0.1-py2.py3-none-any.whl (67kB)\n",
            "\r\u001b[K     |████▉                           | 10kB 23.9MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 20kB 1.7MB/s eta 0:00:01\r\u001b[K     |██████████████▋                 | 30kB 2.5MB/s eta 0:00:01\r\u001b[K     |███████████████████▍            | 40kB 1.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 51kB 2.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 61kB 2.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 71kB 2.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from bert-tensorflow) (1.12.0)\n",
            "Installing collected packages: bert-tensorflow\n",
            "Successfully installed bert-tensorflow-1.0.1\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/bert/optimization.py:87: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PNp-VTPodkiR",
        "colab_type": "text"
      },
      "source": [
        "## 加载BERT hub"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gFr_XpOmdoFK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        },
        "outputId": "3e0f32ff-7ed6-45ab-d04d-6bf0da9cad01"
      },
      "source": [
        "BERT_MODEL_HUB = 'https://tfhub.dev/google/bert_chinese_L-12_H-768_A-12/1'\n",
        "TRAINABLE = True\n",
        "\n",
        "def create_tokenizer_from_hub_module():\n",
        "  with tf.Graph().as_default():\n",
        "    bert_module = hub.Module(BERT_MODEL_HUB)\n",
        "    tokenization_info = bert_module(signature='tokenization_info', as_dict=True)\n",
        "    with tf.Session() as sess:\n",
        "      vocab_file, do_lower_case = sess.run([tokenization_info['vocab_file'], tokenization_info['do_lower_case']])\n",
        "    return bert.tokenization.FullTokenizer(vocab_file=vocab_file, do_lower_case=do_lower_case)\n",
        "\n",
        "tokenizer = create_tokenizer_from_hub_module()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/bert/tokenization.py:125: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/bert/tokenization.py:125: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GSN1CsMJfSYC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tokenizer.tokenize(\"《宝贝》张悬这首歌也是小暖自己从孕期就开始一直循环听的，俏皮好听\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fdN_7M8JfZkw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 665
        },
        "outputId": "5dc38ef2-01bc-4b21-dc66-678e793783c6"
      },
      "source": [
        "MAX_SEQ_LENGTH=256\n",
        "predicate_list_map = [0]*len(predicate_list)\n",
        "for (index, predicate) in enumerate(predicate_list):\n",
        "  predicate_list_map[index] = index\n",
        "\n",
        "train_input_examples = train_data.apply(lambda x: bert.run_classifier.InputExample(guid=None, text_a=x['text'], text_b=None, label=x['labels']), axis=1)\n",
        "train_input_features = conver_examples_to_features(train_input_examples, predicate_list_map, MAX_SEQ_LENGTH, tokenizer)\n"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Writing example 0 of 173108\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Writing example 0 of 173108\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Writing example 10000 of 173108\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Writing example 10000 of 173108\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Writing example 20000 of 173108\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Writing example 20000 of 173108\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Writing example 30000 of 173108\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Writing example 30000 of 173108\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Writing example 40000 of 173108\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Writing example 40000 of 173108\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Writing example 50000 of 173108\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Writing example 50000 of 173108\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Writing example 60000 of 173108\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Writing example 60000 of 173108\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Writing example 70000 of 173108\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Writing example 70000 of 173108\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Writing example 80000 of 173108\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Writing example 80000 of 173108\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Writing example 90000 of 173108\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Writing example 90000 of 173108\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Writing example 100000 of 173108\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Writing example 100000 of 173108\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Writing example 110000 of 173108\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Writing example 110000 of 173108\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Writing example 120000 of 173108\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Writing example 120000 of 173108\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Writing example 130000 of 173108\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Writing example 130000 of 173108\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Writing example 140000 of 173108\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Writing example 140000 of 173108\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Writing example 150000 of 173108\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Writing example 150000 of 173108\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Writing example 160000 of 173108\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Writing example 160000 of 173108\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Writing example 170000 of 173108\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Writing example 170000 of 173108\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RT_Y7YKoT16V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_input_features[0].label_ids"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7HuRpFGhWdEo",
        "colab_type": "text"
      },
      "source": [
        "# 步骤4\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HOWPY-_qNyZK",
        "colab_type": "text"
      },
      "source": [
        "## 创建model_fn_builder\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CWJD9HUZYSKg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_model(is_predicting, input_ids, input_mask, segment_ids, labels, num_labels):\n",
        "  bert_module = hub.Module(BERT_MODEL_HUB, trainable=False)\n",
        "  bert_input = dict(input_ids=input_ids, input_mask=input_mask, segment_ids=segment_ids)\n",
        "  bert_output = bert_module(inputs=bert_input, signature='tokens', as_dict=True)\n",
        "  print(tf.get_variable_scope().name)\n",
        "\n",
        "  output_layer = bert_output['pooled_output']\n",
        "  hidden_size = output_layer.shape[-1].value\n",
        "  print(input_ids)\n",
        "  print([num_labels, hidden_size])\n",
        "  print(num_labels)\n",
        " \n",
        "  output_weights = tf.get_variable('output_weights', [num_labels, hidden_size], initializer=tf.truncated_normal_initializer(stddev=0.02))  \n",
        "  output_bias = tf.get_variable('output_bias', [num_labels], initializer=tf.zeros_initializer())\n",
        "\n",
        "  with tf.variable_scope('loss'):\n",
        "    print(output_weights)\n",
        "\n",
        "    # if not is_predicting:\n",
        "    output_layer = tf.nn.dropout(output_layer, keep_prob=0.9)\n",
        "    logits = tf.matmul(output_layer, output_weights, transpose_b=True)\n",
        "    logits = tf.nn.bias_add(logits, output_bias)\n",
        "    log_probs = tf.sigmoid(logits)\n",
        "    label_ids = tf.cast(labels, tf.float32)\n",
        "    per_example_loss = tf.reduce_sum(tf.nn.sigmoid_cross_entropy_with_logits(logits=logits, labels=label_ids), axis=-1)\n",
        "    loss = tf.reduce_mean(per_example_loss)\n",
        "\n",
        "  return loss, per_example_loss, logits, log_probs\n",
        "     "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RyI5F4Le7Nld",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def model_fn_builder(num_labels, learning_rate, num_train_steps, num_warmup_steps):\n",
        "  def model_fn(features, labels, mode, params):\n",
        "    input_ids = features['input_ids']\n",
        "    input_mask = features['input_mask']\n",
        "    segment_ids = features['segment_ids']\n",
        "    label_ids = features['label_ids']\n",
        "    is_predicting = (mode==tf.estimator.ModeKeys.PREDICT)\n",
        "    (loss, per_example_loss, logits, log_probs) = create_model(\n",
        "        is_predicting, input_ids, input_mask, segment_ids, label_ids, num_labels)\n",
        "\n",
        "    if not is_predicting:\n",
        "      train_op = bert.optimization.create_optimizer(\n",
        "          loss, learning_rate, num_train_steps, num_warmup_steps, use_tpu = False)\n",
        "      def metric_fn(loss, label_ids, log_probs, per_example_loss):\n",
        "        predicted_ids = tf.cast(log_probs > 0.5, tf.int32)\n",
        "        label_ids = tf.cast(label_ids, tf.int32)\n",
        "        elements_equal = tf.cast(tf.equal(predicted_ids, label_ids), tf.int32)\n",
        "        row_predict_ids = tf.reduce_sum(elements_equal, -1)\n",
        "        row_label_ids = tf.reduce_sum(tf.ones_like(label_ids), -1)\n",
        "        accuracy = tf.metrics.accuracy(labels=row_label_ids, predictions=row_predict_ids)\n",
        "        loss = tf.metrics.mean(values=per_example_loss)\n",
        "        return{\n",
        "            'eval_accuracy': accuracy,\n",
        "            'eval_loss': loss\n",
        "        }\n",
        "      if mode == tf.estimator.ModeKeys.TRAIN:\n",
        "        return tf.estimator.EstimatorSpec(mode = mode, loss = loss, train_op = train_op)\n",
        "      else:\n",
        "        eval_metrics = metric_fn(loss, label_ids, log_probs, per_example_loss)\n",
        "        return tf.estimator.EstimatorSpec(mode = mode, loss = loss, eval_metric_ops=eval_metrics)\n",
        "    else:\n",
        "      predictions = {\n",
        "          'logits': logits,\n",
        "          'probabilities': log_probs,\n",
        "      }\n",
        "      return tf.estimator.EstimatorSpec(mode = mode, predictions=predictions)\n",
        "\n",
        "  return model_fn\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b-U6U5apFD6t",
        "colab_type": "text"
      },
      "source": [
        "# 步骤5\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hOwFAyQdN03k",
        "colab_type": "text"
      },
      "source": [
        "## 训练"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-bErFfZXFDZk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "BATCH_SIZE=16\n",
        "LEARNING_RATE = 2e-5\n",
        "NUM_TRAIN_EPOCHS = 3.0\n",
        "WARMUP_PROPORTION = 0.1\n",
        "SAVE_CHECKPOINTS_STEPS = 500\n",
        "SAVE_SUMMARY_STEPS = 100"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C3ScPTIx27FJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "num_train_steps = int(len(train_input_features) / BATCH_SIZE * NUM_TRAIN_EPOCHS)\n",
        "num_warmup_steps = int(num_train_steps * WARMUP_PROPORTION)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eoM-GsL_4TBa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "run_config = tf.estimator.RunConfig(\n",
        "    model_dir = OUTPUT_DIR,\n",
        "    save_summary_steps = SAVE_SUMMARY_STEPS,\n",
        "    save_checkpoints_steps = SAVE_CHECKPOINTS_STEPS\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cd89o9Nc6fir",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "outputId": "0ae6a28b-6808-41fe-ec68-4ca1fb56b2d4"
      },
      "source": [
        "model_fn = model_fn_builder(\n",
        "    num_labels = len(predicate_list),\n",
        "    learning_rate = LEARNING_RATE,\n",
        "    num_train_steps = num_train_steps,\n",
        "    num_warmup_steps = num_warmup_steps\n",
        ")\n",
        "\n",
        "estimator = tf.estimator.Estimator(\n",
        "    model_fn = model_fn,\n",
        "    config = run_config,\n",
        "    params = {'batch_size': BATCH_SIZE}\n",
        ")"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Using config: {'_model_dir': 'gs://bert_classification/training_output', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': 500, '_save_checkpoints_secs': None, '_session_config': allow_soft_placement: true\n",
            "graph_options {\n",
            "  rewrite_options {\n",
            "    meta_optimizer_iterations: ONE\n",
            "  }\n",
            "}\n",
            ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fcbea6b6080>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Using config: {'_model_dir': 'gs://bert_classification/training_output', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': 500, '_save_checkpoints_secs': None, '_session_config': allow_soft_placement: true\n",
            "graph_options {\n",
            "  rewrite_options {\n",
            "    meta_optimizer_iterations: ONE\n",
            "  }\n",
            "}\n",
            ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fcbea6b6080>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fWDR6OV07HZT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_input_fn = input_fn_builder(\n",
        "    features = train_input_features,\n",
        "    seq_length = MAX_SEQ_LENGTH,\n",
        "    is_training = True,\n",
        "    num_labels = len(predicate_list),\n",
        "    drop_remainder = False\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bGvDbPqx690D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from datetime import datetime\n",
        "print(f'Begining Training!')\n",
        "current_time = datetime.now()\n",
        "estimator.train(input_fn = train_input_fn, max_steps=num_train_steps)\n",
        "print('Training took time', datetime.now() - current_time)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JY3dtL0NQuQH",
        "colab_type": "text"
      },
      "source": [
        "# 步骤 6"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "20zNgKFxQwWU",
        "colab_type": "text"
      },
      "source": [
        "## 测试"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yhR81Snd_Tls",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!head /tmp/dev_data.json"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mPdNXhD-Q1H0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 937
        },
        "outputId": "0c3c1e23-7782-4320-e578-1b529fb6715b"
      },
      "source": [
        "\n",
        "test_data, _ = prepare_data('/tmp/dev_data.json', is_training=False, predicate_list=predicate_list, limit=3)\n",
        "print(test_data)\n",
        "test_input_examples = test_data.apply(lambda x: bert.run_classifier.InputExample(guid=None, text_a=x['text'], text_b=None, label=x['labels']), axis=1)\n",
        "test_input_features = conver_examples_to_features(test_input_examples, predicate_list, MAX_SEQ_LENGTH, tokenizer)\n",
        "test_input_fn = input_fn_builder(\n",
        "    features = test_input_features,\n",
        "    seq_length = MAX_SEQ_LENGTH,\n",
        "    is_training = False,\n",
        "    num_labels = len(predicate_list),\n",
        "    drop_remainder = False)\n",
        "estimator.evaluate(input_fn=test_input_fn, steps=None)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "sample {} 0\n",
            "                                                text    labels\n",
            "0  查尔斯·阿兰基斯（Charles Aránguiz），1989年4月17日出生于智利圣地亚哥...    [9, 3]\n",
            "1                                      《离开》是由张宇谱曲，演唱   [7, 22]\n",
            "2  《愤怒的唐僧》由北京吴意波影视文化工作室与优酷电视剧频道联合制作，故事以喜剧元素为主，讲述唐...  [18, 10]\n",
            "INFO:tensorflow:Writing example 0 of 3\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Writing example 0 of 3\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Calling model_fn.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Calling model_fn.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Tensor(\"IteratorGetNext:0\", shape=(?, 256), dtype=int32)\n",
            "[49, 768]\n",
            "49\n",
            "<tf.Variable 'output_weights:0' shape=(49, 768) dtype=float32_ref>\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/bert/optimization.py:27: The name tf.train.get_or_create_global_step is deprecated. Please use tf.compat.v1.train.get_or_create_global_step instead.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/bert/optimization.py:27: The name tf.train.get_or_create_global_step is deprecated. Please use tf.compat.v1.train.get_or_create_global_step instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/bert/optimization.py:32: The name tf.train.polynomial_decay is deprecated. Please use tf.compat.v1.train.polynomial_decay instead.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/bert/optimization.py:32: The name tf.train.polynomial_decay is deprecated. Please use tf.compat.v1.train.polynomial_decay instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/bert/optimization.py:70: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/bert/optimization.py:70: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Done calling model_fn.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Done calling model_fn.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Starting evaluation at 2019-12-09T02:58:58Z\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Starting evaluation at 2019-12-09T02:58:58Z\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Graph was finalized.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Graph was finalized.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Restoring parameters from gs://bert_classification/training_output/model.ckpt-5625\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Restoring parameters from gs://bert_classification/training_output/model.ckpt-5625\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Running local_init_op.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Running local_init_op.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Done running local_init_op.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Done running local_init_op.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished evaluation at 2019-12-09-02:59:47\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished evaluation at 2019-12-09-02:59:47\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saving dict for global step 5625: eval_accuracy = 0.6666667, eval_loss = 4.109061, global_step = 5625, loss = 4.109061\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saving dict for global step 5625: eval_accuracy = 0.6666667, eval_loss = 4.109061, global_step = 5625, loss = 4.109061\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 5625: gs://bert_classification/training_output/model.ckpt-5625\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 5625: gs://bert_classification/training_output/model.ckpt-5625\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'eval_accuracy': 0.6666667,\n",
              " 'eval_loss': 4.109061,\n",
              " 'global_step': 5625,\n",
              " 'loss': 4.109061}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bP9sJmNcZc6W",
        "colab_type": "text"
      },
      "source": [
        "# 步骤7"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uqMWZGtrZe0L",
        "colab_type": "text"
      },
      "source": [
        "## 预测"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zgBZgduNZgql",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_prediction(in_sentences):\n",
        "  input_examples = [bert.run_classifier.InputExample(guid=\"\", text_a = x,\n",
        "                                                     text_b=None, label=[]) for x in in_sentences]\n",
        "\n",
        "  input_features = conver_examples_to_features(input_examples, predicate_list_map,MAX_SEQ_LENGTH,\n",
        "                                                tokenizer)\n",
        "  predict_input_fn = input_fn_builder(features=input_features, seq_length=MAX_SEQ_LENGTH,\n",
        "                                      is_training=False, num_labels=len(predicate_list), drop_remainder=False)\n",
        "  predictions = estimator.predict(predict_input_fn)\n",
        "  return [(sentence, prediction['probabilities'], prediction['logits']) \n",
        "          for sentence, prediction in zip(in_sentences, predictions)]\n",
        "                                                  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gmI6yh31cx-n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predictions = get_prediction([\n",
        "                             \n",
        "                              '《愤怒的唐僧》由北京吴意波影视文化工作室与优酷电视剧频道联合制作，故事以喜剧元素为主，讲述唐僧与佛祖打牌，得罪了佛祖，被踢下人间再渡九九八十一难的故事',\n",
        "                              '李治即位后，萧淑妃受宠，王皇后为了排挤萧淑妃，答应李治让身在感业寺的武则天续起头发，重新纳入后宫',\n",
        "                              ])\n",
        "            \n",
        "# get_prediction([])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xqDIzLGbAhgp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predictions"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nEEYw5jYmL8v",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "725b3c2e-2a7c-4cae-bd04-38bb0a3f8662"
      },
      "source": [
        "labels = []\n",
        "for text, probilities, logits in predictions:\n",
        "  label=[]\n",
        "  for index,prob in enumerate(probilities):\n",
        "    if prob>0.3:\n",
        "      label.append(predicate_list[index])\n",
        "  labels.append(label)\n",
        "\n",
        "labels"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['海拔', '创始人', '祖籍']]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "25Vfl_z6qS2X",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "2f1bc64e-d79f-46b0-bb63-a110768f1015"
      },
      "source": [
        "in_sentences = [\n",
        "                             \n",
        "                              '《愤怒的唐僧》由北京吴意波影视文化工作室与优酷电视剧频道联合制作，故事以喜剧元素为主，讲述唐僧与佛祖打牌，得罪了佛祖，被踢下人间再渡九九八十一难的故事',\n",
        "                              '李治即位后，萧淑妃受宠，王皇后为了排挤萧淑妃，答应李治让身在感业寺的武则天续起头发，重新纳入后宫',\n",
        "                              ]\n",
        "\n",
        "input_examples = [bert.run_classifier.InputExample(guid=\"\", text_a = x,\n",
        "                                            text_b=None, label=[]) for x in in_sentences]\n",
        "\n",
        "input_features = conver_examples_to_features(input_examples, predicate_list_map,MAX_SEQ_LENGTH,\n",
        "                                      tokenizer)\n",
        "predict_input_fn = input_fn_builder(features=input_features, seq_length=MAX_SEQ_LENGTH,\n",
        "                            is_training=False, num_labels=len(predicate_list), drop_remainder=False)\n",
        "predictions = estimator.predict(predict_input_fn)\n"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Writing example 0 of 2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Writing example 0 of 2\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5w3jPRhFpFkO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        },
        "outputId": "2fe7cbd4-c9b4-4584-f823-a65a97ad9159"
      },
      "source": [
        "#[var for var in tf.global_variables() ]\n",
        "estimator.get_variable_value('output_wegihts')"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-46-0a749b258ba1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_variable_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'output_wegihts'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py\u001b[0m in \u001b[0;36mget_variable_value\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    267\u001b[0m     \u001b[0m_check_checkpoint_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 269\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_variable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    270\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    271\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mget_variable_names\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/checkpoint_utils.py\u001b[0m in \u001b[0;36mload_variable\u001b[0;34m(ckpt_dir_or_file, name)\u001b[0m\n\u001b[1;32m     82\u001b[0m     \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m   \u001b[0mreader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_checkpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mckpt_dir_or_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mreader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/pywrap_tensorflow_internal.py\u001b[0m in \u001b[0;36mget_tensor\u001b[0;34m(self, tensor_str)\u001b[0m\n\u001b[1;32m    913\u001b[0m       \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutil\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 915\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mCheckpointReader_GetTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor_str\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m     \u001b[0m__swig_destroy__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_pywrap_tensorflow_internal\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdelete_CheckpointReader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNotFoundError\u001b[0m: Key output_wegihts not found in checkpoint"
          ]
        }
      ]
    }
  ]
}